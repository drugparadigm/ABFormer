{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07ea8646-372b-4b65-96a1-b882b3991e63",
   "metadata": {},
   "source": [
    "## Performing Tests for: \n",
    "### 1. Cluster Separation Quality\n",
    "### 2. Embedding Space Structure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26c5d65-da0c-475f-a32c-83607042f2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "from scipy.spatial.distance import pdist, squareform, cosine\n",
    "from scipy.stats import mannwhitneyu\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "XLSX_PATH = 'data.xlsx'\n",
    "ANTIBINDER_HEAVY_PKL = 'antibinder_heavy.pkl'\n",
    "\n",
    "COL_ADC_ID = \"ADC ID\"\n",
    "COL_ANTIBODY_NAME = \"Antibody Name\"\n",
    "COL_ADC_NAME = \"ADC Name\"\n",
    "COL_HEAVY_SEQ = \"Antibody Heavy Chain Sequence\" \n",
    "COL_LIGHT_SEQ = \"Antibody Light Chain Sequence\" \n",
    "COL_ANTIGEN_SEQ = \"Antigen Sequence\"\n",
    "TOP_N_ANTIGENS = 5\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Output files\n",
    "OUTPUT_DIR = './'\n",
    "\n",
    "ANTIGEN_NAMES = {\n",
    "    0: \"ERBB2\",\n",
    "    1: \"KIT\", \n",
    "    2: \"FGFR2\",\n",
    "    3: \"TNFRSF1A\",\n",
    "    4: \"EGFR\"\n",
    "}\n",
    "\n",
    "def load_data():\n",
    "    print(\"=\"*70)\n",
    "    print(\"LOADING DATA\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    df = pd.read_excel(XLSX_PATH)\n",
    "    print(f\"Loaded {len(df)} samples from {XLSX_PATH}\")\n",
    "    \n",
    "    with open(ANTIBINDER_HEAVY_PKL, 'rb') as f:\n",
    "        antibinder_emb = pickle.load(f)\n",
    "    print(f\"Loaded AntiBinder embeddings: {len(antibinder_emb)} entries\")\n",
    "\n",
    "    aligned_data = []\n",
    "    missing = 0\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        key = row[COL_ADC_ID] if COL_ADC_ID in df.columns else idx\n",
    "        \n",
    "        vec = None\n",
    "        if key in antibinder_emb:\n",
    "            vec = antibinder_emb[key]\n",
    "        elif str(key) in antibinder_emb:\n",
    "            vec = antibinder_emb[str(key)]\n",
    "            \n",
    "        if vec is not None:\n",
    "            if isinstance(vec, torch.Tensor):\n",
    "                vec = vec.detach().cpu().numpy()\n",
    "            \n",
    "            aligned_data.append({\n",
    "                'adc_id': key,\n",
    "                'antibody_name': row.get(COL_ANTIBODY_NAME, 'Unknown'),\n",
    "                'antigen_seq': row[COL_ANTIGEN_SEQ],\n",
    "                'embedding': np.array(vec).flatten()\n",
    "            })\n",
    "        else:\n",
    "            missing += 1\n",
    "    \n",
    "    print(f\"Successfully aligned: {len(aligned_data)} samples\")\n",
    "    print(f\"Missing embeddings: {missing} samples\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return pd.DataFrame(aligned_data)\n",
    "\n",
    "def test1_cluster_quality(df):\n",
    "    print(\"=\"*70)\n",
    "    print(\"TEST 1: CLUSTER SEPARATION QUALITY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Get top antigens\n",
    "    antigen_counts = df['antigen_seq'].value_counts()\n",
    "    top_antigens = antigen_counts.head(TOP_N_ANTIGENS).index.tolist()\n",
    "    df_top = df[df['antigen_seq'].isin(top_antigens)].copy()\n",
    "    \n",
    "    # Create antigen labels\n",
    "    antigen_to_id = {seq: i for i, seq in enumerate(top_antigens)}\n",
    "    df_top['antigen_id'] = df_top['antigen_seq'].map(antigen_to_id)\n",
    "    df_top['antigen_name'] = df_top['antigen_id'].map(ANTIGEN_NAMES)\n",
    "    \n",
    "    print(f\"Analyzing {len(df_top)} samples across {len(top_antigens)} antigens:\")\n",
    "    for i, seq in enumerate(top_antigens):\n",
    "        count = (df_top['antigen_seq'] == seq).sum()\n",
    "        print(f\"  {ANTIGEN_NAMES[i]}: {count} samples\")\n",
    "    \n",
    "    X = np.array(df_top['embedding'].tolist())\n",
    "    labels = df_top['antigen_id'].values\n",
    "    \n",
    "    sil_score = silhouette_score(X, labels, metric='cosine')\n",
    "    db_score = davies_bouldin_score(X, labels)\n",
    "    \n",
    "    print(f\"\\nClustering Quality Metrics (High-Dimensional Space):\")\n",
    "    print(f\"  Silhouette Score: {sil_score:.4f}\")\n",
    "    print(f\"  Davies-Bouldin Index: {db_score:.4f}\")\n",
    "    \n",
    "    print(\"\\nPerforming UMAP projection...\")\n",
    "    reducer = umap.UMAP(n_components=2, random_state=SEED, n_neighbors=15, min_dist=0.1)\n",
    "    X_umap = reducer.fit_transform(X)\n",
    "    \n",
    "    sil_2d = silhouette_score(X_umap, labels, metric='euclidean')\n",
    "    print(f\"  Silhouette Score (2D UMAP): {sil_2d:.4f}\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    for antigen_id in sorted(df_top['antigen_id'].unique()):\n",
    "        mask = df_top['antigen_id'] == antigen_id\n",
    "        subset = X_umap[mask]\n",
    "        name = ANTIGEN_NAMES[antigen_id]\n",
    "        count = mask.sum()\n",
    "        \n",
    "        ax.scatter(subset[:, 0], subset[:, 1], \n",
    "                  label=f\"{name} (n={count})\",\n",
    "                  alpha=0.7, s=80, edgecolor='white', linewidth=0.5)\n",
    "    \n",
    "    ax.set_xlabel('UMAP Dimension 1', fontsize=12)\n",
    "    ax.set_ylabel('UMAP Dimension 2', fontsize=12)\n",
    "    ax.set_title('AntiBinder Embeddings: Domain Generalization to ADC Antigens\\n' +\n",
    "                 f'(Trained on MET, Applied to {len(top_antigens)} Novel Targets)',\n",
    "                 fontsize=13, weight='bold')\n",
    "    ax.legend(loc='best', frameon=True, fontsize=10)\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(OUTPUT_DIR + 'test1_cluster_quality.png', dpi=600, bbox_inches='tight')\n",
    "    print(f\"\\nSaved: test1_cluster_quality.png\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return {\n",
    "        'silhouette_hd': sil_score,\n",
    "        'davies_bouldin': db_score,\n",
    "        'silhouette_2d': sil_2d\n",
    "    }\n",
    "\n",
    "def test2_distance_analysis(df):\n",
    "    print(\"=\"*70)\n",
    "    print(\"TEST 2: EMBEDDING SPACE STRUCTURE ANALYSIS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    antigen_counts = df['antigen_seq'].value_counts()\n",
    "    top_antigens = antigen_counts.head(TOP_N_ANTIGENS).index.tolist()\n",
    "    df_top = df[df['antigen_seq'].isin(top_antigens)].copy()\n",
    "    \n",
    "    antigen_to_id = {seq: i for i, seq in enumerate(top_antigens)}\n",
    "    df_top['antigen_id'] = df_top['antigen_seq'].map(antigen_to_id)\n",
    "    \n",
    "    X = np.array(df_top['embedding'].tolist())\n",
    "    \n",
    "    print(\"Computing pairwise distances...\")\n",
    "    dist_matrix = squareform(pdist(X, metric='cosine'))\n",
    "    \n",
    "    intra_distances = []\n",
    "    inter_distances = []\n",
    "    \n",
    "    labels = df_top['antigen_id'].values\n",
    "    n = len(labels)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            dist = dist_matrix[i, j]\n",
    "            if labels[i] == labels[j]:\n",
    "                intra_distances.append(dist)\n",
    "            else:\n",
    "                inter_distances.append(dist)\n",
    "    \n",
    "    intra_distances = np.array(intra_distances)\n",
    "    inter_distances = np.array(inter_distances)\n",
    "    \n",
    "    print(f\"\\nDistance Statistics:\")\n",
    "    print(f\"  Intra-antigen distances: {len(intra_distances)} pairs\")\n",
    "    print(f\"    Mean: {intra_distances.mean():.4f}\")\n",
    "    print(f\"    Std:  {intra_distances.std():.4f}\")\n",
    "    print(f\"  Inter-antigen distances: {len(inter_distances)} pairs\")\n",
    "    print(f\"    Mean: {inter_distances.mean():.4f}\")\n",
    "    print(f\"    Std:  {inter_distances.std():.4f}\")\n",
    "    \n",
    "    u_stat, p_value = mannwhitneyu(intra_distances, inter_distances, alternative='less')\n",
    "    print(f\"\\nMann-Whitney U test (intra < inter):\")\n",
    "    print(f\"  U-statistic: {u_stat:.2e}\")\n",
    "    print(f\"  p-value: {p_value:.2e}\")\n",
    "    \n",
    "    ratio = inter_distances.mean() / intra_distances.mean()\n",
    "    print(f\"  Inter/Intra Ratio: {ratio:.2f}x (Inter-cluster distances are {ratio:.2f} times larger)\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    axes[0].hist(intra_distances, bins=50, alpha=0.7, label='Intra-antigen', density=True, color='blue')\n",
    "    axes[0].hist(inter_distances, bins=50, alpha=0.7, label='Inter-antigen', density=True, color='red')\n",
    "    axes[0].axvline(intra_distances.mean(), color='blue', linestyle='--', linewidth=2, label='Intra mean')\n",
    "    axes[0].axvline(inter_distances.mean(), color='red', linestyle='--', linewidth=2, label='Inter mean')\n",
    "    axes[0].set_xlabel('Cosine Distance', fontsize=11)\n",
    "    axes[0].set_ylabel('Density', fontsize=11)\n",
    "    axes[0].set_title('Distance Distribution', fontsize=12, weight='bold')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    \n",
    "    data_box = pd.DataFrame({\n",
    "        'Distance': np.concatenate([intra_distances, inter_distances]),\n",
    "        'Type': ['Intra-antigen']*len(intra_distances) + ['Inter-antigen']*len(inter_distances)\n",
    "    })\n",
    "    sns.boxplot(data=data_box, x='Type', y='Distance', ax=axes[1], palette=['blue', 'red'])\n",
    "    axes[1].set_title(f'Distance Comparison\\n(p < 0.001)', \n",
    "                     fontsize=12, weight='bold')\n",
    "    axes[1].set_ylabel('Cosine Distance', fontsize=11)\n",
    "    axes[1].grid(alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(OUTPUT_DIR + 'test2_distance_analysis.png', dpi=600, bbox_inches='tight')\n",
    "    print(f\"\\nSaved: test2_distance_analysis.png\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return {\n",
    "        'intra_mean': intra_distances.mean(),\n",
    "        'inter_mean': inter_distances.mean(),\n",
    "        'p_value': p_value,\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ANTIBINDER DOMAIN GENERALIZATION ANALYSIS\")\n",
    "    print(\"Validating Transfer from MET to Diverse ADC Antigens\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    df = load_data()\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    results['test1'] = test1_cluster_quality(df)\n",
    "    results['test2'] = test2_distance_analysis(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d859fe5-1e2b-4afc-8875-c4b342847c33",
   "metadata": {},
   "source": [
    "## Performing Tests for: \n",
    "### 3. t-sne\n",
    "### 4. Y-Scrambling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f1ce6c-8df2-45e8-93c3-05de496999b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "\n",
    "from ADCNet import PredictModel\n",
    "from AB_Data import AB_Data\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "DATA_FILE = \"data/data.xlsx\"\n",
    "EMBED_PATHS = [\n",
    "    \"Embeddings/antibinder_heavy.pkl\",\n",
    "    \"Embeddings/Light.pkl\",\n",
    "    \"Embeddings/Antigen.pkl\",\n",
    "]\n",
    "\n",
    "import torch, numpy as np, random\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "PATH_BEFORE_TRAINING = \"model_weights/modified_model.pth\" \n",
    "PATH_AFTER_TRAINING = \"ckpts/ADC_1_best_model.pth\" \n",
    "\n",
    "BATCH_SIZE = 32\n",
    "features_storage = []\n",
    "\n",
    "def get_fc2_hook(module, input, output):\n",
    "    \"\"\" Hooks into fc2 to capture the learned embedding.This bypasses the final prediction layer to see what the model 'learned'.\"\"\"\n",
    "    features_storage.append(output.detach().cpu())\n",
    "\n",
    "def extract_data(model, dataloader, device, description):\n",
    "    \n",
    "    print(f\"[{description}] Extracting embeddings...\")\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    hook_handle = model.fc2.register_forward_hook(get_fc2_hook)\n",
    "    features_storage.clear()\n",
    "    \n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            x1, x1maccs, x2, x2maccs, t1, t2, t3, aac1, aac2, aac3, t4, y = batch\n",
    "\n",
    "            x1, x2 = x1.to(device), x2.to(device)\n",
    "            x1maccs, x2maccs = x1maccs.to(device), x2maccs.to(device)\n",
    "            t1, t2, t3, t4 = t1.to(device), t2.to(device), t3.to(device), t4.to(device)\n",
    "            aac1, aac2, aac3 = aac1.to(device), aac2.to(device), aac3.to(device)\n",
    "\n",
    "            if t4.dim() == 1: t4 = t4.unsqueeze(1)\n",
    "            if t1.dim() == 1: t1 = t1.unsqueeze(1)\n",
    "            if t2.dim() == 1: t2 = t2.unsqueeze(1)\n",
    "            if t3.dim() == 1: t3 = t3.unsqueeze(1)\n",
    "            if aac1.dim() == 1: aac1 = aac1.unsqueeze(1)\n",
    "\n",
    "            logits = model(x1, x1maccs, x2, x2maccs, t1, t2, t3, aac1, aac2, aac3, t4)\n",
    "            \n",
    "            preds = torch.sigmoid(logits)\n",
    "            \n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(y)\n",
    "\n",
    "    hook_handle.remove()\n",
    "\n",
    "    X = torch.cat(features_storage).numpy()\n",
    "    y = torch.cat(all_labels).numpy()\n",
    "    preds = torch.cat(all_preds).numpy()\n",
    "    \n",
    "    return X, y, preds\n",
    "\n",
    "def run_tsne(full_loader):\n",
    "    model = PredictModel().to(DEVICE)\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(PATH_BEFORE_TRAINING, map_location=DEVICE), strict=False)\n",
    "        print(\"Loaded 'Before' weights.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not load 'Before' weights. Using random init. ({e})\")\n",
    "    \n",
    "    X_before, y_before, _ = extract_data(model, full_loader, DEVICE, \"Before Training\")\n",
    "\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(PATH_AFTER_TRAINING, map_location=DEVICE))\n",
    "        print(\"Loaded 'After' weights.\")\n",
    "    except Exception as e:\n",
    "        print(f\"CRITICAL ERROR: Could not load trained checkpoint! {e}\")\n",
    "        return\n",
    "\n",
    "    X_after, y_after, _ = extract_data(model, full_loader, DEVICE, \"After Training\")\n",
    "\n",
    "    n_samples = len(y_before)\n",
    "    perp = min(30, int(n_samples / 10)) if n_samples > 0 else 30\n",
    "    print(f\"Running t-SNE on {n_samples} samples (Perplexity: {perp})...\")\n",
    "    \n",
    "    tsne = TSNE(n_components=2, perplexity=perp, random_state=42, init='pca', learning_rate='auto')\n",
    "    Z_before = tsne.fit_transform(X_before)\n",
    "    Z_after = tsne.fit_transform(X_after)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "    colors = {0: 'orange', 1: 'green'}\n",
    "    labels = {0: 'Negative', 1: 'Positive'}\n",
    "\n",
    "    for label_val in [0, 1]:\n",
    "        mask = (y_before == label_val)\n",
    "        axes[0].scatter(Z_before[mask, 0], Z_before[mask, 1], c=colors[label_val], label=labels[label_val], \n",
    "                        alpha=0.6, s=40, edgecolors='w', linewidth=0.5)\n",
    "    axes[0].set_title(\"Before Training\\n(Untrained Space)\", fontsize=14)\n",
    "    axes[0].legend()\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    for label_val in [0, 1]:\n",
    "        mask = (y_after == label_val)\n",
    "        axes[1].scatter(Z_after[mask, 0], Z_after[mask, 1], c=colors[label_val], label=labels[label_val], \n",
    "                        alpha=0.6, s=40, edgecolors='w', linewidth=0.5)\n",
    "    axes[1].set_title(\"After Training\\n(ABFormer Learned Space)\", fontsize=14)\n",
    "    axes[1].legend()\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(\"t-sne.png\", dpi=600)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def run_yscramble_test(full_loader):\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TASK 2: Y-Scrambling Validation Test\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    model = PredictModel().to(DEVICE)\n",
    "    model.load_state_dict(torch.load(PATH_AFTER_TRAINING, map_location=DEVICE))\n",
    "\n",
    "    X, y_true, y_preds = extract_data(model, full_loader, DEVICE, \"Y-Scramble Evaluation\")\n",
    "\n",
    "    np.random.seed(42)\n",
    "    y_scrambled = np.random.permutation(y_true)\n",
    "\n",
    "    auc_true = roc_auc_score(y_true, y_preds)\n",
    "    auc_scram = roc_auc_score(y_scrambled, y_preds)\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    print(f\"TRUE LABELS AUC: {auc_true:.4f}\")\n",
    "    print(f\"SCRAMBLED Y  AUC: {auc_scram:.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    perp = min(30, int(len(y_true) / 10))\n",
    "    tsne = TSNE(n_components=2, perplexity=perp, random_state=42, init='pca', learning_rate='auto')\n",
    "    Z = tsne.fit_transform(X)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "    colors = {0: 'orange', 1: 'green'}\n",
    "    labels = {0: 'Negative', 1: 'Positive'}\n",
    "\n",
    "    for label_val in [0, 1]:\n",
    "        mask = (y_true == label_val)\n",
    "        axes[0].scatter(Z[mask, 0], Z[mask, 1], c=colors[label_val], label=labels[label_val], \n",
    "                        alpha=0.6, s=40, edgecolors='w', linewidth=0.5)\n",
    "    axes[0].set_title(f\"True Labels\\nAUC: {auc_true:.3f}\", fontsize=14, fontweight='bold')\n",
    "    axes[0].legend()\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    for label_val in [0, 1]:\n",
    "        mask = (y_scrambled == label_val)\n",
    "        axes[1].scatter(Z[mask, 0], Z[mask, 1], c=colors[label_val], label=labels[label_val], \n",
    "                        alpha=0.6, s=40, edgecolors='w', linewidth=0.5)\n",
    "    axes[1].set_title(f\"Y-Scrambled Labels\\nAUC: {auc_scram:.3f} (Random)\", fontsize=14, fontweight='bold')\n",
    "    axes[1].legend()\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(\"Y_Scramble_Test.png\", dpi=600)\n",
    "    plt.show()\n",
    "    # print(\"SAVED: Y_Scramble_Test.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Loading Dataset (Merging Train+Val+Test for visualization)...\")\n",
    "    data_handler = AB_Data(DATA_FILE, EMBED_PATHS)\n",
    "    \n",
    "    train, val, test = data_handler.get_dataloaders(batch_size=BATCH_SIZE, seed=1)\n",
    "    \n",
    "    full_dataset = ConcatDataset([\n",
    "        data_handler.train_dataset, \n",
    "        data_handler.valid_dataset, \n",
    "        data_handler.test_dataset\n",
    "    ])\n",
    "    full_loader = DataLoader(full_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    run_tsne(full_loader)\n",
    "    run_yscramble_test(full_loader)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ABFormernew",
   "language": "python",
   "name": "abformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
